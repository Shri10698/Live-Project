#!/usr/bin/env python
# coding: utf-8

# In[1]:


import pandas as pd
import numpy as np
import pickle
import matplotlib.pyplot as plt
get_ipython().run_line_magic('matplotlib', 'inline')
import warnings
warnings.filterwarnings('ignore')
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split


# # DATASET:

# # Rgression Model For Average Price:

# In[2]:


df = pd.read_csv('avocado.csv')
df


# above dataset shows us the information about avacoda fruit in which we can see 14 columns and 18249 rows. 
# So we have various 14 features from its we have to prdict the region and average price i.e. per piece price. so region and average price are our target variables while building regression and classificaton model.there is one unnamed column which is not useful so we will drop it.

# In[3]:


df.shape


# its the shape of our data 14 features with 18249 rows.

# Following is the individual description or meaning for each column
Column Name	                                            Description
Unnamed	                                           SNo.
Date	                                           The date of the observation
AveragePrice	                                   the average price of a single avocado
Total Volume	                                   Total number of avocados sold
4046	                                           Total number of avocados with PLU 4046 sold
4225	                                           Total number of avocados with PLU 4225 sold
4770	                                           Total number of avocados with PLU 4770 sold
Total Bags	                                       Total Number of Bags sold
Small Bags	                                       Total Number of Small Bags sold
Large Bags	                                       Total Number of Large Bags sold
XLarge Bags	                                       Total Number of XLarge Bags sold
type	                                           Organic or Conventional
year	                                           The year of observation
region	                                           the city or region of the observation
# In[4]:


df.describe()


# its the overall statastial health of our data where can see mean standard deviation max and min data.

# In[5]:


df.drop(columns=['Unnamed: 0'],axis=1,inplace=True)
df.head()


# I have dropped here column unnamed which is not useful.

# In[6]:


df.info()


# here we can see in our data three columns contian object data we have to convert it into int using encoder.

# In[7]:


df.isnull().sum()


# our dataset does not contain any null values.lets proceed ahead

# In[8]:


df.type.value_counts()


# In[9]:


plt.figure(figsize=(5,6))
sns.countplot(df['type'])
plt.show()


# In[10]:


df.year.value_counts()


# In[11]:


plt.figure(figsize=(6,5))
sns.countplot(df['year'])
plt.show()


# In[12]:


for column in df.columns:
    if df[column].dtype == object:
        print(str(column) + ':' + str(df[column].unique()))
        print(df[column].value_counts())
        print('*********************************************************')
        


# In[13]:


df.rename(columns={'4046':'Small HASS sold',
                          '4225':'Large HASS sold',
                          '4770':'XLarge HASS sold'},inplace=True)
df


# In[14]:


sns.distplot(df["AveragePrice"],axlabel="Distribution of average price")


# This the distribution for average price. most of the avearge price lies between 1.0 and 1.8

# In[15]:


df['Date']=pd.to_datetime(df['Date'])
df['Month']=df['Date'].apply(lambda x:x.month)
df['Day']=df['Date'].apply(lambda x:x.day)
df['Year'] =df['Date'].apply(lambda x:x.year)
df.drop(['Date'],axis=1,inplace=True)


# In[16]:


df


# In[17]:


plt.figure(figsize=(10,10))
sns.lineplot(x="Month", y="AveragePrice", hue='type', data=df)
plt.show()


# distrbibution of the average price over the month. and in 10 th month average price for both type of avacoda is high.

# In[18]:


plt.figure(figsize=(10,10))
sns.lineplot(x="Year", y="AveragePrice", hue='type', data=df)
plt.show()


# for 2015 price is lower than others and for 2017 its higher than all the years.

# In[19]:


plt.figure(figsize=(10,10))
sns.lineplot(x="Day", y="AveragePrice", hue='type', data=df)
plt.show()


# In the start middle and end of the price looking higher for the month.

# In[20]:


df = pd.get_dummies(df, columns=['type'],drop_first=True)
df.head()


# In[21]:


df['type_organic'].value_counts()


# 9126 is count for conventional and 9123 is count for organic

# In[22]:


sns.boxplot(x="type_organic", y="AveragePrice", data=df)


# Organic avacados are more expensive than conventional.

# In[23]:


df['region'].value_counts()


# In[24]:


df.groupby("region")["AveragePrice"].sum().sort_values(ascending=False).plot(kind="bar",figsize=(15,5))


# avocado's price varies with region having hartford Springfield highest and houstan cheapest.

# In[25]:


df.hist(figsize=(14,13));


# In[26]:


df.plot(kind='box',figsize=(15,15),layout=(3,5),sharex=False,subplots=True);


# In[27]:


from sklearn.preprocessing import LabelEncoder


# In[28]:


encoder = LabelEncoder()
df['region'] = encoder.fit_transform(df['region'])


# In[29]:


df


# In[30]:


df.corr()


# In[ ]:





# In[31]:


df_corr = df.corr().abs()

plt.figure(figsize =(13,10))
sns.heatmap(df_corr,annot = True, annot_kws={'size':9})
plt.show()


# In[32]:


df.shape


# In[33]:


x = df.drop(columns=['AveragePrice'],axis=1)
y= df['AveragePrice']


# In[34]:


from sklearn.feature_selection import f_classif,SelectKBest


# In[35]:


best_features = SelectKBest(score_func=f_classif,k=10)
fit = best_features.fit(x,y)
df_scores = pd.DataFrame(fit.scores_)
df_columns = pd.DataFrame(x.columns)

feature_scores = pd.concat([df_columns,df_scores],axis=1)
feature_scores.columns = (['Feature_Name','Score'])

print(feature_scores.nlargest(10,'Score'))


# In[36]:


df.columns[[13,1,0,3,2,4,5,6,8,12]]


# In[37]:


new_x = df[['Year', 'Total Volume', 'AveragePrice', 'Large HASS sold',
       'Small HASS sold', 'XLarge HASS sold', 'Total Bags', 'Small Bags',
       'XLarge Bags', 'Day']]
new_x


# In[38]:


scaler = StandardScaler()
X_scaled = scaler.fit_transform(new_x)


# In[39]:


from sklearn.linear_model import LinearRegression
lr = LinearRegression()
from sklearn.metrics import r2_score


# In[40]:


MaxAccu=0
MaxR=0
for i in range(0,200):
    x_train,x_test,y_train,y_test = train_test_split(X_scaled,y,random_state = i,test_size = 0.20)
    lr.fit(x_train,y_train)
    pred_train = lr.predict(x_train)
    pred_test = lr.predict(x_test)
    acc=r2_score(y_test,pred_test)
    print('accuracy',acc,'random_state',i)
    
    if acc>MaxAccu:
        MaxAccu = acc
        MaxR=i
        print('accuracy',MaxAccu,'random_state',i)


# In[41]:


print('Best Acuracy',MaxAccu,'Random State',MaxR)


# In[42]:


from sklearn.model_selection import cross_val_score
scr = cross_val_score(lr,X_scaled,y,cv=3)
print("Cross Validation Score for Logistic Classification Model is:-",scr.mean())


# In[43]:


from sklearn.metrics import mean_absolute_error,mean_squared_error


# In[64]:


mae = mean_absolute_error(y_test,pred_test)
print(mae)


# In[45]:


mse = mean_squared_error(y_test,pred_test)
mse


# In[46]:


rmse = np.sqrt(mse)
rmse


# In[47]:


plt.scatter(y_test,pred_test)
plt.xlable = ('Actual Price of Avocado')
plt.ylable = ('Predicated Price of Avocado')
plt.title = ('Actual Price v/s Predicated Price')
plt.show()


# from above scatterplot I could clerly see that the actual and predicated are alomost same.

# In[48]:


from sklearn.ensemble import RandomForestRegressor


# In[49]:


rt =  RandomForestRegressor()
rt.fit(x_train,y_train)
predrt = rt.predict(x_test)
print('accuracy',r2_score(y_test,predrt))


# In[50]:


mae = mean_absolute_error(y_test,predrt)
mse = mean_squared_error(y_test,predrt)
rmse = np.sqrt(mse)
print('Mean Squared Erro=',mse,'Root Mean Squared Error=',rmse)


# In[51]:


from sklearn.svm import SVR


# In[52]:


svr =  SVR()
svr.fit(x_train,y_train)
predrt = svr.predict(x_test)
print('accuracy',r2_score(y_test,predrt))


# In[53]:


mae = mean_absolute_error(y_test,predrt)
mse = mean_squared_error(y_test,predrt)
rmse = np.sqrt(mse)
print('Mean Squared Erro=',mse,'Root Mean Squared Error=',rmse)


# In[54]:


from sklearn.ensemble import AdaBoostRegressor


# In[55]:


ad = AdaBoostRegressor()
ad.fit(x_train,y_train)
predrt = ad.predict(x_test)
print('accuracy',r2_score(y_test,predrt))


# In[56]:


mae = mean_absolute_error(y_test,predrt)
mse = mean_squared_error(y_test,predrt)
rmse = np.sqrt(mse)
print('Mean Squared Erro=',mse,'Root Mean Squared Error=',rmse)


# In[57]:


from sklearn.ensemble import BaggingRegressor


# In[58]:


bg = BaggingRegressor()
bg.fit(x_train,y_train)
predrt = bg.predict(x_test)
print('accuracy',r2_score(y_test,predrt))


# In[59]:


mae = mean_absolute_error(y_test,predrt)
mse = mean_squared_error(y_test,predrt)
rmse = np.sqrt(mse)
print('Mean Squared Erro=',mse,'Root Mean Squared Error=',rmse)


# from above model accuracy scores is high and error scores are for linearRegression. so LinearRegrssion would be best fit forthe above the problem statement.

# In[65]:


import pickle
file = open('Avacoda.pkl', 'wb')
pickle.dump(lr, file)
model=open('Avacoda.pkl', 'rb')
Avacoda=pickle.load(model)


# In[ ]:




